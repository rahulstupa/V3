{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd5caa27",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##imports\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import warnings\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data.distributed\n",
    "from easydict import EasyDict as edict\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('./')\n",
    "\n",
    "from data_process.ttnet_dataloader import create_train_val_dataloader, create_test_dataloader\n",
    "from models.model_utils import create_model, load_pretrained_model, make_data_parallel, resume_model, get_num_parameters\n",
    "from models.model_utils import freeze_model\n",
    "from utils.train_utils import create_optimizer, create_lr_scheduler, get_saved_state, save_checkpoint\n",
    "from utils.train_utils import reduce_tensor, to_python_float\n",
    "from utils.misc import AverageMeter, ProgressMeter\n",
    "from utils.logger import Logger\n",
    "#from config.config import parse_configs\n",
    "from utils.misc import make_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a52a4f",
   "metadata": {},
   "source": [
    "###### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17997582",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def parse_configs():\n",
    "    parser = argparse.ArgumentParser(description='TTNet Implementation')\n",
    "    parser.add_argument('--seed', type=int, default=2020, help='re-produce the results with seed random')\n",
    "    parser.add_argument('--saved_fn', type=str, default='ttnet', metavar='FN', help='The name using for saving logs, models,...')\n",
    "    ####################################################################\n",
    "    ##############     Model configs            ###################\n",
    "    ####################################################################\n",
    "    parser.add_argument('-a', '--arch', type=str, default='ttnet', metavar='ARCH', help='The name of the model architecture')\n",
    "    parser.add_argument('--dropout_p', type=float, default=0.5, metavar='P', help='The dropout probability of the model')\n",
    "    parser.add_argument('--multitask_learning', action='store_true', help='If true, the weights of different losses will be learnt (train).'\n",
    "                             'If false, a regular sum of different losses will be applied')\n",
    "    parser.add_argument('--no_local', action='store_true', help='If true, no local stage for ball detection.')\n",
    "    parser.add_argument('--no_event', action='store_true', help='If true, no event spotting detection.')\n",
    "    parser.add_argument('--no_seg', action='store_true', help='If true, no segmentation module.')\n",
    "    parser.add_argument('--pretrained_path', type=str, default=None, metavar='PATH', help='the path of the pretrained checkpoint')\n",
    "    parser.add_argument('--overwrite_global_2_local', action='store_true', help='If true, the weights of the local stage will be overwritten by the global stage.')\n",
    "\n",
    "    ####################################################################\n",
    "    ##############     Dataloader and Running configs            #######\n",
    "    ####################################################################\n",
    "    parser.add_argument('--working-dir', type=str, default='../../', metavar='PATH', help='the ROOT working directory')\n",
    "    parser.add_argument('--no-val', action='store_true', help='If true, use all data for training, no validation set')\n",
    "    parser.add_argument('--no-test', action='store_true', help='If true, dont evaluate the model on the test set')\n",
    "    parser.add_argument('--val-size', type=float, default=0.2, help='The size of validation set')\n",
    "    parser.add_argument('--smooth-labelling', action='store_true', help='If true, smoothly make the labels of event spotting')\n",
    "    parser.add_argument('--num_samples', type=int, default=None, help='Take a subset of the dataset to run and debug')\n",
    "    parser.add_argument('--num_workers', type=int, default=4, help='Number of threads for loading data')\n",
    "    parser.add_argument('--batch_size', type=int, default=8, help='mini-batch size (default: 8), this is the total'\n",
    "                             'batch size of all GPUs on the current node when using'\n",
    "                             'Data Parallel or Distributed Data Parallel')\n",
    "    parser.add_argument('--print_freq', type=int, default=50, metavar='N', help='print frequency (default: 50)')\n",
    "    parser.add_argument('--checkpoint_freq', type=int, default=2, metavar='N', help='frequency of saving checkpoints (default: 2)')\n",
    "    parser.add_argument('--sigma', type=float, default=1., metavar='SIGMA', help='standard deviation of the 1D Gaussian for the ball position target')\n",
    "    parser.add_argument('--thresh_ball_pos_mask', type=float, default=0.05, metavar='THRESH', help='the lower thresh for the 1D Gaussian of the ball position target')\n",
    "    ####################################################################\n",
    "    ##############     Training strategy            ###################\n",
    "    ####################################################################\n",
    "\n",
    "    parser.add_argument('--start_epoch', type=int, default=1, metavar='N', help='the starting epoch')\n",
    "    parser.add_argument('--num_epochs', type=int, default=30, metavar='N', help='number of total epochs to run')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3, metavar='LR', help='initial learning rate')\n",
    "    parser.add_argument('--minimum_lr', type=float, default=1e-7, metavar='MIN_LR', help='minimum learning rate during training')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M', help='momentum')\n",
    "    parser.add_argument('-wd', '--weight_decay', type=float, default=0., metavar='WD', help='weight decay (default: 1e-6)')\n",
    "    parser.add_argument('--optimizer_type', type=str, default='adam', metavar='OPTIMIZER', help='the type of optimizer, it can be sgd or adam')\n",
    "    parser.add_argument('--lr_type', type=str, default='plateau', metavar='SCHEDULER', help='the type of the learning rate scheduler (steplr or ReduceonPlateau)')\n",
    "    parser.add_argument('--lr_factor', type=float, default=0.5, metavar='FACTOR', help='reduce the learning rate with this factor')\n",
    "    parser.add_argument('--lr_step_size', type=int, default=5, metavar='STEP_SIZE', help='step_size of the learning rate when using steplr scheduler')\n",
    "    parser.add_argument('--lr_patience', type=int, default=3, metavar='N', help='patience of the learning rate when using ReduceoPlateau scheduler')\n",
    "    parser.add_argument('--earlystop_patience', type=int, default=None, metavar='N', help='Early stopping the training process if performance is not improved within this value')\n",
    "    parser.add_argument('--freeze_global', action='store_true', help='If true, no update/train weights for the global stage of ball detection.')\n",
    "    parser.add_argument('--freeze_local', action='store_true', help='If true, no update/train weights for the local stage of ball detection.')\n",
    "    parser.add_argument('--freeze_event', action='store_true', help='If true, no update/train weights for the event module.')\n",
    "    parser.add_argument('--freeze_seg', action='store_true', help='If true, no update/train weights for the segmentation module.')\n",
    "\n",
    "    ####################################################################\n",
    "    ##############     Loss weight            ###################\n",
    "    ####################################################################\n",
    "    parser.add_argument('--bce_weight', type=float, default=0.5, help='The weight of BCE loss in segmentation module, the dice_loss weight = 1- bce_weight')\n",
    "    parser.add_argument('--global_weight', type=float, default=1., help='The weight of loss of the global stage for ball detection')\n",
    "    parser.add_argument('--local_weight', type=float, default=1., help='The weight of loss of the local stage for ball detection')\n",
    "    parser.add_argument('--event_weight', type=float, default=1., help='The weight of loss of the event spotting module')\n",
    "    parser.add_argument('--seg_weight', type=float, default=1., help='The weight of BCE loss in segmentation module')\n",
    "\n",
    "    ####################################################################\n",
    "    ##############     Distributed Data Parallel            ############\n",
    "    ####################################################################\n",
    "    parser.add_argument('--world-size', default=-1, type=int, metavar='N', help='number of nodes for distributed training')\n",
    "    parser.add_argument('--rank', default=-1, type=int, metavar='N', help='node rank for distributed training')\n",
    "    parser.add_argument('--dist-url', default='tcp://127.0.0.1:29500', type=str, help='url used to set up distributed training')\n",
    "    parser.add_argument('--dist-backend', default='nccl', type=str, help='distributed backend')\n",
    "    parser.add_argument('--gpu_idx', default=0, type=int, help='GPU index to use.')\n",
    "    parser.add_argument('--no_cuda', action='store_true', help='If true, cuda is not used.')\n",
    "    parser.add_argument('--multiprocessing-distributed', action='store_true', help='Use multi-processing distributed training to launch '\n",
    "                             'N processes per node, which has N GPUs. This is the '\n",
    "                             'fastest way to use PyTorch for either single node or '\n",
    "                             'multi node data parallel training')\n",
    "    ####################################################################\n",
    "    ##############     Evaluation configurations     ###################\n",
    "    ####################################################################\n",
    "    parser.add_argument('--evaluate', action='store_true', help='only evaluate the model, not training')\n",
    "    parser.add_argument('--resume_path', type=str, default=None, metavar='PATH', help='the path of the resumed checkpoint')\n",
    "    parser.add_argument('--use_best_checkpoint', action='store_true', help='If true, choose the best model on val set, otherwise choose the last model')\n",
    "    parser.add_argument('--seg_thresh', type=float, default=0.5, help='threshold of the segmentation output')\n",
    "    parser.add_argument('--event_thresh', type=float, default=0.5, help='threshold of the event spotting output')\n",
    "    parser.add_argument('--save_test_output', action='store_true', help='If true, the image of testing phase will be saved')\n",
    "\n",
    "    ####################################################################\n",
    "    ##############     Demonstration configurations     ###################\n",
    "    ####################################################################\n",
    "    parser.add_argument('--video_path', type=str, default=None, metavar='PATH', help='the path of the video that needs to demo')\n",
    "    parser.add_argument('--output_format', type=str, default='text', metavar='PATH', help='the type of the demo output')\n",
    "    parser.add_argument('--show_image', action='store_true', help='If true, show the image during demostration')\n",
    "    parser.add_argument('--save_demo_output', action='store_true', help='If true, the image of demonstration phase will be saved')\n",
    "\n",
    "    configs = edict(vars(parser.parse_args([])))\n",
    "\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b75dcd46",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def config_process(configs):\n",
    "    ####################################################################\n",
    "    ############## Hardware configurations ############################\n",
    "    ####################################################################\n",
    "    configs.device = torch.device('cpu' if configs.no_cuda else 'cuda')\n",
    "    configs.ngpus_per_node = torch.cuda.device_count()\n",
    "\n",
    "    configs.pin_memory = True\n",
    "\n",
    "    ####################################################################\n",
    "    ##############     Data configs            ###################\n",
    "    ####################################################################\n",
    "    configs.dataset_dir = os.path.join(configs.working_dir, 'dataset')\n",
    "    configs.train_game_list = ['game_1']#, 'game_2', 'game_3', 'game_4', 'game_5']\n",
    "    configs.test_game_list = ['test_1']#, 'test_2', 'test_3', 'test_4', 'test_5', 'test_6', 'test_7']\n",
    "    configs.events_dict = {\n",
    "        'bounce': 0,\n",
    "        'net': 1,\n",
    "        'empty_event': 2\n",
    "    }\n",
    "    configs.events_weights_loss_dict = {\n",
    "        'bounce': 1.,\n",
    "        'net': 3.,\n",
    "    }\n",
    "    configs.events_weights_loss = (configs.events_weights_loss_dict['bounce'], configs.events_weights_loss_dict['net'])\n",
    "    configs.num_events = len(configs.events_weights_loss_dict)  # Just \"bounce\" and \"net hits\"\n",
    "    configs.num_frames_sequence = 9\n",
    "\n",
    "    configs.org_size = (1920, 1080)\n",
    "    configs.input_size = (320, 128)\n",
    "\n",
    "    configs.tasks = ['global', 'local', 'event', 'seg']\n",
    "    if configs.no_local:\n",
    "        if 'local' in configs.tasks:\n",
    "            configs.tasks.remove('local')\n",
    "        if 'event' in configs.tasks:\n",
    "            configs.tasks.remove('event')\n",
    "    if configs.no_event:\n",
    "        if 'event' in configs.tasks:\n",
    "            configs.tasks.remove('event')\n",
    "    if configs.no_seg:\n",
    "        if 'seg' in configs.tasks:\n",
    "            configs.tasks.remove('seg')\n",
    "\n",
    "    # Compose loss weight for tasks, normalize the weights later\n",
    "    loss_weight_dict = {\n",
    "        'global': configs.global_weight,\n",
    "        'local': configs.local_weight,\n",
    "        'event': configs.event_weight,\n",
    "        'seg': configs.seg_weight\n",
    "    }\n",
    "    configs.tasks_loss_weight = [loss_weight_dict[task] for task in configs.tasks]\n",
    "\n",
    "    configs.freeze_modules_list = []\n",
    "    if configs.freeze_global:\n",
    "        configs.freeze_modules_list.append('ball_global_stage')\n",
    "    if configs.freeze_local:\n",
    "        configs.freeze_modules_list.append('ball_local_stage')\n",
    "    if configs.freeze_event:\n",
    "        configs.freeze_modules_list.append('events_spotting')\n",
    "    if configs.freeze_seg:\n",
    "        configs.freeze_modules_list.append('segmentation')\n",
    "\n",
    "    ####################################################################\n",
    "    ############## logs, Checkpoints, and results dir ########################\n",
    "    ####################################################################\n",
    "    configs.checkpoints_dir = os.path.join(configs.working_dir, 'checkpoints', configs.saved_fn)\n",
    "    configs.logs_dir = os.path.join(configs.working_dir, 'logs', configs.saved_fn)\n",
    "    configs.use_best_checkpoint = True\n",
    "\n",
    "    if configs.use_best_checkpoint:\n",
    "        configs.saved_weight_name = os.path.join(configs.checkpoints_dir, '{}_best.pth'.format(configs.saved_fn))\n",
    "    else:\n",
    "        configs.saved_weight_name = os.path.join(configs.checkpoints_dir, '{}.pth'.format(configs.saved_fn))\n",
    "\n",
    "    configs.results_dir = os.path.join(configs.working_dir, 'results')\n",
    "\n",
    "    make_folder(configs.checkpoints_dir)\n",
    "    make_folder(configs.logs_dir)\n",
    "    make_folder(configs.results_dir)\n",
    "\n",
    "    if configs.save_test_output:\n",
    "        configs.saved_dir = os.path.join(configs.results_dir, configs.saved_fn)\n",
    "        make_folder(configs.saved_dir)\n",
    "\n",
    "    if configs.save_demo_output:\n",
    "        configs.save_demo_dir = os.path.join(configs.results_dir, 'demo', configs.saved_fn)\n",
    "        make_folder(configs.save_demo_dir)\n",
    "\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c9677e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHASE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4990c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = parse_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd762f8",
   "metadata": {
    "code_folding": [
     0,
     19
    ]
   },
   "outputs": [],
   "source": [
    "if PHASE == 1: \n",
    "    #Phase 1\n",
    "    configs.working_dir      = \"../\"\n",
    "    configs.saved_fn         = 'ttnet_1st_phase_opentt'\n",
    "    configs.no_val           = True\n",
    "    configs.batch_size       = 24\n",
    "    configs.num_workers      = 8\n",
    "    configs.lr               = 0.001 \n",
    "    configs.lr_type          = 'step_lr' \n",
    "    configs.lr_step_size     = 10 \n",
    "    configs.lr_factor        = 0.1\n",
    "    configs.gpu_idx          = 0 \n",
    "    configs.global_weight    = 5. \n",
    "    configs.seg_weight       = 1.\n",
    "    configs.no_event         = True\n",
    "    configs.no_local         = True\n",
    "    configs.print_freq       = 500\n",
    "    configs.smooth_labelling = True\n",
    "\n",
    "if PHASE == 2:\n",
    "    #Phase 2\n",
    "    configs.working_dir                = \"../\"\n",
    "    configs.batch_size                 = 24\n",
    "    configs.num_workers                = 8\n",
    "    configs.saved_fn                   = 'ttnet_2nd_phase_opentt' \n",
    "    configs.no_val                     = True  \n",
    "    configs.lr                         = 0.001 \n",
    "    configs.lr_type                    = 'step_lr' \n",
    "    configs.lr_step_size               =  10 \n",
    "    configs.lr_factor                  = 0.1 \n",
    "    configs.gpu_idx                    = 0 \n",
    "    configs.global_weight              = 0. \n",
    "    configs.event_weight               = 2. \n",
    "    configs.local_weight               = 1. \n",
    "    configs.pretrained_path            = \"../checkpoints/ttnet_1st_phase_opentt/ttnet_1st_phase_opentt_epoch_30.pth\"\n",
    "    configs.overwrite_global_2_local   = True\n",
    "    configs.freeze_global              = True\n",
    "    configs.smooth_labelling           = True\n",
    "    configs.freeze_seg                 = True\n",
    "    configs.sigma                      = 1.0\n",
    "    configs.print_freq                 = 500   \n",
    "    \n",
    "if PHASE == 3:\n",
    "    #Phase 3\n",
    "    configs.working_dir       = \"../\"\n",
    "    configs.saved_fn          = 'ttnet_3nd_phase' \n",
    "    configs.batch_size        = 24\n",
    "    configs.num_workers       = 8\n",
    "    \n",
    "    configs.no_val            = True  \n",
    "    configs.lr                = 0.0001 \n",
    "    configs.lr_type           = 'step_lr' \n",
    "    configs.lr_step_size      =  10 \n",
    "    configs.lr_factor         = 0.2 \n",
    "    configs.gpu_idx           = 0 \n",
    "    configs.global_weight     = 1. \n",
    "    configs.event_weight      = 1. \n",
    "    configs.local_weight      = 1. \n",
    "    configs.pretrained_path   = \"../checkpoints/ttnet_2nd_phase_opentt/ttnet_2nd_phase_opentt_epoch_30.pth\"\n",
    "    configs.smooth_labelling  = True\n",
    "#     configs.sigma             = 1.0\n",
    "    configs.print_freq        = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40df5235",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = config_process(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1224ac14",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.freeze_modules_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7aecd8e",
   "metadata": {
    "code_folding": [
     0,
     6
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stupa/miniconda3/envs/ttnet/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "if configs.seed is not None:\n",
    "    random.seed(configs.seed)\n",
    "    np.random.seed(configs.seed)\n",
    "    torch.manual_seed(configs.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "if configs.gpu_idx is not None:\n",
    "    warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                      'disable data parallelism.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c82968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs.distributed = configs.world_size > 1 or configs.multiprocessing_distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "373f5aac",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: 0 for training\n"
     ]
    }
   ],
   "source": [
    "if configs.gpu_idx is not None:\n",
    "    print(\"Use GPU: {} for training\".format(configs.gpu_idx))\n",
    "    configs.device = torch.device('cuda:{}'.format(configs.gpu_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9f1addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs.is_master_node = (not configs.distributed) or (configs.distributed and (configs.rank % configs.ngpus_per_node == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5db5311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.is_master_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b5298d8",
   "metadata": {
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 20:56:19,882: logger.py - info(), at Line 38:INFO:\n",
      ">>> Created a new logger\n",
      "2022-12-19 20:56:19,883: logger.py - info(), at Line 38:INFO:\n",
      ">>> configs: {'seed': 2020, 'saved_fn': 'ttnet_3nd_phase', 'arch': 'ttnet', 'dropout_p': 0.5, 'multitask_learning': False, 'no_local': False, 'no_event': False, 'no_seg': False, 'pretrained_path': '../checkpoints/ttnet_2nd_phase_opentt/ttnet_2nd_phase_opentt_epoch_30.pth', 'overwrite_global_2_local': False, 'working_dir': '../', 'no_val': True, 'no_test': False, 'val_size': 0.2, 'smooth_labelling': True, 'num_samples': None, 'num_workers': 8, 'batch_size': 24, 'print_freq': 500, 'checkpoint_freq': 2, 'sigma': 1.0, 'thresh_ball_pos_mask': 0.05, 'start_epoch': 1, 'num_epochs': 30, 'lr': 0.0001, 'minimum_lr': 1e-07, 'momentum': 0.9, 'weight_decay': 0.0, 'optimizer_type': 'adam', 'lr_type': 'step_lr', 'lr_factor': 0.2, 'lr_step_size': 10, 'lr_patience': 3, 'earlystop_patience': None, 'freeze_global': False, 'freeze_local': False, 'freeze_event': False, 'freeze_seg': False, 'bce_weight': 0.5, 'global_weight': 1.0, 'local_weight': 1.0, 'event_weight': 1.0, 'seg_weight': 1.0, 'world_size': -1, 'rank': -1, 'dist_url': 'tcp://127.0.0.1:29500', 'dist_backend': 'nccl', 'gpu_idx': 0, 'no_cuda': False, 'multiprocessing_distributed': False, 'evaluate': False, 'resume_path': None, 'use_best_checkpoint': True, 'seg_thresh': 0.5, 'event_thresh': 0.5, 'save_test_output': False, 'video_path': None, 'output_format': 'text', 'show_image': False, 'save_demo_output': False, 'device': device(type='cuda', index=0), 'ngpus_per_node': 1, 'pin_memory': True, 'dataset_dir': '../dataset', 'train_game_list': ['game_1'], 'test_game_list': ['test_1'], 'events_dict': {'bounce': 0, 'net': 1, 'empty_event': 2}, 'events_weights_loss_dict': {'bounce': 1.0, 'net': 3.0}, 'events_weights_loss': [1.0, 3.0], 'num_events': 2, 'num_frames_sequence': 9, 'org_size': [1920, 1080], 'input_size': [320, 128], 'tasks': ['global', 'local', 'event', 'seg'], 'tasks_loss_weight': [1.0, 1.0, 1.0, 1.0], 'freeze_modules_list': [], 'checkpoints_dir': '../checkpoints/ttnet_3nd_phase', 'logs_dir': '../logs/ttnet_3nd_phase', 'saved_weight_name': '../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_best.pth', 'results_dir': '../results', 'distributed': False, 'is_master_node': True}\n"
     ]
    }
   ],
   "source": [
    "if configs.is_master_node:\n",
    "    logger = Logger(configs.logs_dir, configs.saved_fn)\n",
    "    logger.info('>>> Created a new logger')\n",
    "    logger.info('>>> configs: {}'.format(configs))\n",
    "    tb_writer = SummaryWriter(log_dir=os.path.join(configs.logs_dir, 'tensorboard'))\n",
    "else:\n",
    "    logger = None\n",
    "    tb_writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905af3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f371c30c",
   "metadata": {},
   "source": [
    "##### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b65af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a43d6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_data_parallel(model, configs)\n",
    "\n",
    "# Freeze model\n",
    "model = freeze_model(model, configs.freeze_modules_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa42fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c886975",
   "metadata": {},
   "source": [
    "#### Train supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59f5b750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 20:56:21,892: logger.py - info(), at Line 38:INFO:\n",
      "number of trained parameters of the model: 16091813\n"
     ]
    }
   ],
   "source": [
    "if configs.is_master_node:\n",
    "    num_parameters = get_num_parameters(model)\n",
    "    logger.info('number of trained parameters of the model: {}'.format(num_parameters))\n",
    "\n",
    "optimizer = create_optimizer(configs, model)\n",
    "lr_scheduler = create_lr_scheduler(optimizer, configs)\n",
    "best_val_loss = np.inf\n",
    "earlystop_count = 0\n",
    "is_best = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4791cd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.is_master_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e19fcaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 20:56:22,031: logger.py - info(), at Line 38:INFO:\n",
      "loaded pretrained model at ../checkpoints/ttnet_2nd_phase_opentt/ttnet_2nd_phase_opentt_epoch_30.pth\n",
      "2022-12-19 20:56:22,032: logger.py - info(), at Line 38:INFO:\n",
      ">>> Loading dataset & getting dataloader...\n"
     ]
    }
   ],
   "source": [
    "if configs.pretrained_path is not None:\n",
    "    model = load_pretrained_model(model, configs.pretrained_path, configs.gpu_idx, configs.overwrite_global_2_local)\n",
    "    if logger is not None:\n",
    "        logger.info('loaded pretrained model at {}'.format(configs.pretrained_path))\n",
    "\n",
    "# optionally resume from a checkpoint\n",
    "if configs.resume_path is not None:\n",
    "    checkpoint = resume_model(configs.resume_path, configs.arch, configs.gpu_idx)\n",
    "    if hasattr(model, 'module'):\n",
    "        model.module.load_state_dict(checkpoint['state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "    best_val_loss = checkpoint['best_val_loss']\n",
    "    earlystop_count = checkpoint['earlystop_count']\n",
    "    configs.start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "if logger is not None:\n",
    "    logger.info(\">>> Loading dataset & getting dataloader...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1deae37",
   "metadata": {},
   "source": [
    "##### Datalaoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "997db578",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, train_sampler = create_train_val_dataloader(configs)\n",
    "test_loader = create_test_dataloader(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60824e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f927081d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(train_loader, model, optimizer, epoch, configs, logger):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "\n",
    "    progress = ProgressMeter(len(train_loader), [batch_time, data_time, losses],\n",
    "                             prefix=\"Train - Epoch: [{}/{}]\".format(epoch, configs.num_epochs))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for batch_idx, (resized_imgs, org_ball_pos_xy, global_ball_pos_xy, target_events, target_seg) in enumerate(\n",
    "            tqdm(train_loader)):\n",
    "        data_time.update(time.time() - start_time)\n",
    "        batch_size = resized_imgs.size(0)\n",
    "        target_seg = target_seg.to(configs.device, non_blocking=True)\n",
    "        resized_imgs = resized_imgs.to(configs.device, non_blocking=True).float()\n",
    "        pred_ball_global, pred_ball_local, pred_events, pred_seg, local_ball_pos_xy, total_loss, _ = model(\n",
    "            resized_imgs, org_ball_pos_xy, global_ball_pos_xy, target_events, target_seg)\n",
    "        # For torch.nn.DataParallel case\n",
    "        if (not configs.distributed) and (configs.gpu_idx is None):\n",
    "            total_loss = torch.mean(total_loss)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # compute gradient and perform backpropagation\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if configs.distributed:\n",
    "            reduced_loss = reduce_tensor(total_loss.data, configs.world_size)\n",
    "        else:\n",
    "            reduced_loss = total_loss.data\n",
    "        losses.update(to_python_float(reduced_loss), batch_size)\n",
    "        # measure elapsed time\n",
    "        torch.cuda.synchronize()\n",
    "        batch_time.update(time.time() - start_time)\n",
    "\n",
    "        # Log message\n",
    "        if logger is not None:\n",
    "            if ((batch_idx + 1) % configs.print_freq) == 0:\n",
    "                logger.info(progress.get_message(batch_idx))\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "704b64a6",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate_one_epoch(val_loader, model, epoch, configs, logger):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "\n",
    "    progress = ProgressMeter(len(val_loader), [batch_time, data_time, losses],\n",
    "                             prefix=\"Evaluate - Epoch: [{}/{}]\".format(epoch, configs.num_epochs))\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        for batch_idx, (resized_imgs, org_ball_pos_xy, global_ball_pos_xy, target_events, target_seg) in enumerate(\n",
    "                tqdm(val_loader)):\n",
    "            data_time.update(time.time() - start_time)\n",
    "            batch_size = resized_imgs.size(0)\n",
    "            target_seg = target_seg.to(configs.device, non_blocking=True)\n",
    "            resized_imgs = resized_imgs.to(configs.device, non_blocking=True).float()\n",
    "            pred_ball_global, pred_ball_local, pred_events, pred_seg, local_ball_pos_xy, total_loss, _ = model(\n",
    "                resized_imgs, org_ball_pos_xy, global_ball_pos_xy, target_events, target_seg)\n",
    "\n",
    "            # For torch.nn.DataParallel case\n",
    "            if (not configs.distributed) and (configs.gpu_idx is None):\n",
    "                total_loss = torch.mean(total_loss)\n",
    "\n",
    "            if configs.distributed:\n",
    "                reduced_loss = reduce_tensor(total_loss.data, configs.world_size)\n",
    "            else:\n",
    "                reduced_loss = total_loss.data\n",
    "            losses.update(to_python_float(reduced_loss), batch_size)\n",
    "            # measure elapsed time\n",
    "            torch.cuda.synchronize()\n",
    "            batch_time.update(time.time() - start_time)\n",
    "\n",
    "            # Log message\n",
    "            if logger is not None:\n",
    "                if ((batch_idx + 1) % configs.print_freq) == 0:\n",
    "                    logger.info(progress.get_message(batch_idx))\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3130f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fd4bb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 20:56:22,656: logger.py - info(), at Line 38:INFO:\n",
      "number of batches in train set: 161\n",
      "2022-12-19 20:56:22,657: logger.py - info(), at Line 38:INFO:\n",
      "number of batches in test set: 21\n"
     ]
    }
   ],
   "source": [
    "if logger is not None:\n",
    "    logger.info('number of batches in train set: {}'.format(len(train_loader)))\n",
    "    if val_loader is not None:\n",
    "        logger.info('number of batches in val set: {}'.format(len(val_loader)))\n",
    "    logger.info('number of batches in test set: {}'.format(len(test_loader)))\n",
    "\n",
    "if configs.evaluate:\n",
    "    assert val_loader is not None, \"The validation should not be None\"\n",
    "    val_loss = evaluate_one_epoch(val_loader, model, configs.start_epoch - 1, configs, logger)\n",
    "    print('Evaluate, val_loss: {}'.format(val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb21b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss = evaluate_one_epoch(test_loader, model, configs.start_epoch - 1, configs, logger)\n",
    "# val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6084a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7fcf510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 20:56:24,354: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 20:56:24,355: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 1/30 ===================================\n",
      "2022-12-19 20:56:24,356: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 20:56:24,357: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [1/30] learning rate: 1.00e-04\n",
      "100%|██████████| 161/161 [01:12<00:00,  2.21it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.74it/s]\n",
      "2022-12-19 20:57:49,178: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 20:57:49,179: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 2/30 ===================================\n",
      "2022-12-19 20:57:49,180: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 20:57:49,181: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [2/30] learning rate: 1.00e-04\n",
      "100%|██████████| 161/161 [01:21<00:00,  1.97it/s]\n",
      "100%|██████████| 21/21 [00:11<00:00,  1.76it/s]\n",
      "2022-12-19 20:59:23,109: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 20:59:23,110: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 3/30 ===================================\n",
      "2022-12-19 20:59:23,111: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 20:59:23,111: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [3/30] learning rate: 1.00e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:21<00:00,  1.97it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.72it/s]\n",
      "2022-12-19 21:00:56,974: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:00:56,975: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 4/30 ===================================\n",
      "2022-12-19 21:00:56,976: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:00:56,976: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [4/30] learning rate: 1.00e-04\n",
      "100%|██████████| 161/161 [01:21<00:00,  1.98it/s]\n",
      "100%|██████████| 21/21 [00:11<00:00,  1.77it/s]\n",
      "2022-12-19 21:02:30,350: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:02:30,351: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 5/30 ===================================\n",
      "2022-12-19 21:02:30,352: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:02:30,352: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [5/30] learning rate: 1.00e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:21<00:00,  1.97it/s]\n",
      "100%|██████████| 21/21 [00:11<00:00,  1.80it/s]\n",
      "2022-12-19 21:04:03,922: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:04:03,923: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 6/30 ===================================\n",
      "2022-12-19 21:04:03,924: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:04:03,924: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [6/30] learning rate: 1.00e-04\n",
      "100%|██████████| 161/161 [01:22<00:00,  1.96it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.72it/s]\n",
      "2022-12-19 21:05:38,385: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:05:38,386: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 7/30 ===================================\n",
      "2022-12-19 21:05:38,386: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:05:38,387: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [7/30] learning rate: 1.00e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:21<00:00,  1.96it/s]\n",
      "100%|██████████| 21/21 [00:11<00:00,  1.77it/s]\n",
      "2022-12-19 21:07:12,253: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:07:12,254: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 8/30 ===================================\n",
      "2022-12-19 21:07:12,255: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:07:12,256: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [8/30] learning rate: 1.00e-04\n",
      "100%|██████████| 161/161 [01:22<00:00,  1.96it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.68it/s]\n",
      "2022-12-19 21:08:47,184: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:08:47,185: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 9/30 ===================================\n",
      "2022-12-19 21:08:47,185: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:08:47,186: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [9/30] learning rate: 1.00e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:21<00:00,  1.97it/s]\n",
      "100%|██████████| 21/21 [00:11<00:00,  1.76it/s]\n",
      "2022-12-19 21:10:21,070: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:10:21,072: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 10/30 ===================================\n",
      "2022-12-19 21:10:21,072: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:10:21,073: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [10/30] learning rate: 1.00e-04\n",
      "100%|██████████| 161/161 [01:22<00:00,  1.95it/s]\n",
      "100%|██████████| 21/21 [00:11<00:00,  1.77it/s]\n",
      "2022-12-19 21:11:55,683: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:11:55,683: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 11/30 ===================================\n",
      "2022-12-19 21:11:55,684: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:11:55,685: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [11/30] learning rate: 2.00e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_10.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:22<00:00,  1.95it/s]\n",
      "100%|██████████| 21/21 [00:11<00:00,  1.76it/s]\n",
      "2022-12-19 21:13:30,020: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:13:30,021: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 12/30 ===================================\n",
      "2022-12-19 21:13:30,021: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:13:30,022: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [12/30] learning rate: 2.00e-05\n",
      "100%|██████████| 161/161 [01:22<00:00,  1.95it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.74it/s]\n",
      "2022-12-19 21:15:04,860: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:15:04,861: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 13/30 ===================================\n",
      "2022-12-19 21:15:04,861: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:15:04,862: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [13/30] learning rate: 2.00e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_12.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:22<00:00,  1.96it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.73it/s]\n",
      "2022-12-19 21:16:39,211: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:16:39,212: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 14/30 ===================================\n",
      "2022-12-19 21:16:39,213: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:16:39,213: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [14/30] learning rate: 2.00e-05\n",
      "100%|██████████| 161/161 [01:22<00:00,  1.94it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.68it/s]\n",
      "2022-12-19 21:18:14,720: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:18:14,721: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 15/30 ===================================\n",
      "2022-12-19 21:18:14,721: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:18:14,722: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [15/30] learning rate: 2.00e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_14.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:22<00:00,  1.95it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.74it/s]\n",
      "2022-12-19 21:19:49,265: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:19:49,266: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 16/30 ===================================\n",
      "2022-12-19 21:19:49,266: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:19:49,267: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [16/30] learning rate: 2.00e-05\n",
      "100%|██████████| 161/161 [01:22<00:00,  1.95it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.72it/s]\n",
      "2022-12-19 21:21:24,306: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:21:24,307: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 17/30 ===================================\n",
      "2022-12-19 21:21:24,307: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:21:24,308: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [17/30] learning rate: 2.00e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:22<00:00,  1.96it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.74it/s]\n",
      "2022-12-19 21:22:58,423: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:22:58,423: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 18/30 ===================================\n",
      "2022-12-19 21:22:58,424: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:22:58,424: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [18/30] learning rate: 2.00e-05\n",
      "100%|██████████| 161/161 [01:22<00:00,  1.95it/s]\n",
      "100%|██████████| 21/21 [00:11<00:00,  1.75it/s]\n",
      "2022-12-19 21:24:33,134: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:24:33,135: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 19/30 ===================================\n",
      "2022-12-19 21:24:33,135: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:24:33,136: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [19/30] learning rate: 2.00e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:22<00:00,  1.95it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.73it/s]\n",
      "2022-12-19 21:26:08,049: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:26:08,051: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 20/30 ===================================\n",
      "2022-12-19 21:26:08,052: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:26:08,053: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [20/30] learning rate: 2.00e-05\n",
      "100%|██████████| 161/161 [01:22<00:00,  1.95it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.74it/s]\n",
      "2022-12-19 21:27:43,067: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:27:43,068: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 21/30 ===================================\n",
      "2022-12-19 21:27:43,068: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:27:43,068: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [21/30] learning rate: 4.00e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:22<00:00,  1.95it/s]\n",
      "100%|██████████| 21/21 [00:11<00:00,  1.76it/s]\n",
      "2022-12-19 21:29:17,649: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:29:17,650: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 22/30 ===================================\n",
      "2022-12-19 21:29:17,651: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:29:17,652: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [22/30] learning rate: 4.00e-06\n",
      "100%|██████████| 161/161 [01:22<00:00,  1.96it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.73it/s]\n",
      "2022-12-19 21:30:52,112: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:30:52,113: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 23/30 ===================================\n",
      "2022-12-19 21:30:52,114: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:30:52,115: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [23/30] learning rate: 4.00e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_22.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:23<00:00,  1.94it/s]\n",
      "100%|██████████| 21/21 [00:11<00:00,  1.75it/s]\n",
      "2022-12-19 21:32:27,302: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:32:27,303: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 24/30 ===================================\n",
      "2022-12-19 21:32:27,304: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:32:27,304: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [24/30] learning rate: 4.00e-06\n",
      "100%|██████████| 161/161 [01:22<00:00,  1.94it/s]\n",
      "100%|██████████| 21/21 [00:11<00:00,  1.75it/s]\n",
      "2022-12-19 21:34:02,444: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:34:02,445: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 25/30 ===================================\n",
      "2022-12-19 21:34:02,446: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:34:02,446: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [25/30] learning rate: 4.00e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_24.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:22<00:00,  1.95it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.73it/s]\n",
      "2022-12-19 21:35:36,941: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:35:36,942: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 26/30 ===================================\n",
      "2022-12-19 21:35:36,943: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:35:36,943: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [26/30] learning rate: 4.00e-06\n",
      "100%|██████████| 161/161 [01:22<00:00,  1.95it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.74it/s]\n",
      "2022-12-19 21:37:11,865: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:37:11,866: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 27/30 ===================================\n",
      "2022-12-19 21:37:11,867: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:37:11,867: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [27/30] learning rate: 4.00e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:22<00:00,  1.94it/s]\n",
      "100%|██████████| 21/21 [00:11<00:00,  1.76it/s]\n",
      "2022-12-19 21:38:46,730: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:38:46,731: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 28/30 ===================================\n",
      "2022-12-19 21:38:46,732: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:38:46,732: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [28/30] learning rate: 4.00e-06\n",
      "100%|██████████| 161/161 [01:22<00:00,  1.94it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.71it/s]\n",
      "2022-12-19 21:40:22,076: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:40:22,078: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 29/30 ===================================\n",
      "2022-12-19 21:40:22,078: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:40:22,079: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [29/30] learning rate: 4.00e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_28.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:22<00:00,  1.94it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.73it/s]\n",
      "2022-12-19 21:41:57,138: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:41:57,139: logger.py - info(), at Line 38:INFO:\n",
      "=================================== 30/30 ===================================\n",
      "2022-12-19 21:41:57,140: logger.py - info(), at Line 38:INFO:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "2022-12-19 21:41:57,141: logger.py - info(), at Line 38:INFO:\n",
      ">>> Epoch: [30/30] learning rate: 4.00e-06\n",
      "100%|██████████| 161/161 [01:22<00:00,  1.96it/s]\n",
      "100%|██████████| 21/21 [00:12<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save a checkpoint at ../checkpoints/ttnet_3nd_phase/ttnet_3nd_phase_epoch_30.pth\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(configs.start_epoch, configs.num_epochs + 1):\n",
    "    # Get the current learning rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr = param_group['lr']\n",
    "    if logger is not None:\n",
    "        logger.info('{}'.format('*-' * 40))\n",
    "        logger.info('{} {}/{} {}'.format('=' * 35, epoch, configs.num_epochs, '=' * 35))\n",
    "        logger.info('{}'.format('*-' * 40))\n",
    "        logger.info('>>> Epoch: [{}/{}] learning rate: {:.2e}'.format(epoch, configs.num_epochs, lr))\n",
    "\n",
    "    if configs.distributed:\n",
    "        train_sampler.set_epoch(epoch)\n",
    "    # train for one epoch\n",
    "    train_loss = train_one_epoch(train_loader, model, optimizer, epoch, configs, logger)\n",
    "    loss_dict = {'train': train_loss}\n",
    "    if not configs.no_val:\n",
    "        val_loss = evaluate_one_epoch(val_loader, model, epoch, configs, logger)\n",
    "        is_best = val_loss <= best_val_loss\n",
    "        best_val_loss = min(val_loss, best_val_loss)\n",
    "        loss_dict['val'] = val_loss\n",
    "\n",
    "    if not configs.no_test:\n",
    "        test_loss = evaluate_one_epoch(test_loader, model, epoch, configs, logger)\n",
    "        loss_dict['test'] = test_loss\n",
    "    # Write tensorboard\n",
    "    if tb_writer is not None:\n",
    "        tb_writer.add_scalars('Loss', loss_dict, epoch)\n",
    "    # Save checkpoint\n",
    "    if configs.is_master_node and (is_best or ((epoch % configs.checkpoint_freq) == 0)):\n",
    "        saved_state = get_saved_state(model, optimizer, lr_scheduler, epoch, configs, best_val_loss,\n",
    "                                      earlystop_count)\n",
    "        save_checkpoint(configs.checkpoints_dir, configs.saved_fn, saved_state, is_best, epoch)\n",
    "    # Check early stop training\n",
    "    if configs.earlystop_patience is not None:\n",
    "        earlystop_count = 0 if is_best else (earlystop_count + 1)\n",
    "        print_string = ' |||\\t earlystop_count: {}'.format(earlystop_count)\n",
    "        if configs.earlystop_patience <= earlystop_count:\n",
    "            print_string += '\\n\\t--- Early stopping!!!'\n",
    "            break\n",
    "        else:\n",
    "            print_string += '\\n\\t--- Continue training..., earlystop_count: {}'.format(earlystop_count)\n",
    "        if logger is not None:\n",
    "            logger.info(print_string)\n",
    "    # Adjust learning rate\n",
    "    if configs.lr_type == 'plateau':\n",
    "        assert (not configs.no_val), \"Only use plateau when having validation set\"\n",
    "        lr_scheduler.step(val_loss)\n",
    "    else:\n",
    "        lr_scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77ae2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tb_writer is not None:\n",
    "    tb_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b994a399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b744e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3419361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90858987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e7b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435a114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
